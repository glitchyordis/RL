{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tqdm\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "from IPython.display import clear_output\n",
    "from IPython import display \n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# check and use GPU if available if not use CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, activation, layers=[32,32,16]):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define layers with ReLU activation\n",
    "        self.linear1 = torch.nn.Linear(input_size, layers[0])\n",
    "        self.activation1 = torch.nn.ReLU()\n",
    "        self.linear2 = torch.nn.Linear(layers[0], layers[1])\n",
    "        self.activation2 = torch.nn.ReLU()\n",
    "        self.linear3 = torch.nn.Linear(layers[1], layers[2])\n",
    "        self.activation3 = torch.nn.ReLU()\n",
    "\n",
    "        self.output_layer = torch.nn.Linear(layers[2], output_size)\n",
    "        self.output_activation = activation\n",
    "\n",
    "        torch.nn.init.xavier_normal_(self.linear1.weight)\n",
    "        torch.nn.init.xavier_normal_(self.linear2.weight)\n",
    "        torch.nn.init.xavier_normal_(self.linear3.weight)\n",
    "        torch.nn.init.xavier_normal_(self.output_layer.weight)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Forward pass through the layers\n",
    "        x = self.activation1(self.linear1(inputs))\n",
    "        x = self.activation2(self.linear2(x))\n",
    "        x = self.activation3(self.linear3(x))\n",
    "        x = self.output_activation(self.output_layer(x))\n",
    "        return x\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310_2env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
